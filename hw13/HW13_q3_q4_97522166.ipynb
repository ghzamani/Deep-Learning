{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "05e4mKftC8BP"
      },
      "outputs": [],
      "source": [
        "#@title Student Information\n",
        "#@markdown Enter the following info and run the cell:\n",
        "Name = \"Ghazal ZamaniNejad\" #@param {type:\"string\"}\n",
        "StudentNumber = 97522166 #@param {type:\"integer\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf-jnHngag-m"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJBzDr12K3bf"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0twGcAkFWiG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from functools import reduce\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import IPython\n",
        "from IPython.display import clear_output \n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from transformers import TFBertModel, BertTokenizer\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGw9iBLGU9Cu",
        "outputId": "6257bef7-eb0d-4b84-c296-fba5a809c29b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi # check if gpu mode is selected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JqUZuEo8G_p"
      },
      "source": [
        "We will use a dataset consists of questions where a previously given single supporting fact, potentially amongst a set of other irrelevant facts, provides the answer. We first test one of the simplest cases of this, by asking for the location of a person, e.g. “$Mary$ $travelled$ $to$ $the$ $office.$ $Where$ $is$ $Mary?$”. It can be considered the\n",
        "simplest case of some real world QA datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsvVnfvfGnib"
      },
      "source": [
        "About the dataset: https://research.fb.com/downloads/babi/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OlahJ1OrKjd"
      },
      "source": [
        "Lets download the dataset:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_dp3WT7FW8E"
      },
      "source": [
        "# 1. LSTM- Q&A\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "259V3MeC9G55"
      },
      "source": [
        "## 1.2 Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u_xDAfovXf7"
      },
      "source": [
        "Our model takes a discrete set of inputs $x_{1}, ..., x_{n}$ that are to be stored in the memory, a query $q$, and outputs an answer $a$. Each of the $x_{i}$, $q$, and $a$ contains symbols coming from a dictionary with $V$ words. The model writes all $x$ to the memory up to a fixed buffer size, and then finds a continuous representation for the $x$ and $q$. The continuous representation is then processed via multiple hops to\n",
        "output $a$. This allows backpropagation of the error signal through multiple memory accesses back to the input during training. The overall model is shown in the next figure. During training, all three embedding matrices $A, B$ and $C$, as well as $W$ are jointly learned by minimizing a standard cross-entropy loss between $aˆ$ and the true\n",
        "label $a$. Training is performed using stochastic gradient descent.\n",
        "\n",
        "\n",
        "Delve more deeply into the details: https://arxiv.org/pdf/1503.08895.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tx-wpcdQJfpk"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!wget https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz\n",
        "!tar -xvzf babi_tasks_1-20_v1-2.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBYgDigJanwz"
      },
      "outputs": [],
      "source": [
        "challenges = [\n",
        "    'qa1_single-supporting-fact',\n",
        "    'qa2_two-supporting-facts',\n",
        "]\n",
        "train_file_path = f'/content/tasks_1-20_v1-2/en-10k/{challenges[0]}_train.txt'\n",
        "test_file_path = f'/content/tasks_1-20_v1-2/en-10k/{challenges[0]}_test.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCBfH4qrrKjL"
      },
      "outputs": [],
      "source": [
        "def word_tokenizer(sent):\n",
        "    return [ x.strip() for x in re.split('(\\W+)', sent) if x.strip()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WLJmevS-Dy6"
      },
      "source": [
        "According to the dataset (bAbi tasks), we need to prepare the data for training the model. With the next function we parse the dataset and manufactore it in desired way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzksSX8drKjP"
      },
      "outputs": [],
      "source": [
        "def parse_stories(lines, only_supporting=False, tokenize = True):\n",
        "    '''Parse stories provided in the bAbi tasks format\n",
        "    If only_supporting is true, only the sentences\n",
        "    that support the answer are kept.\n",
        "    '''\n",
        "    data = []\n",
        "    story = []\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        nid, line = line.split(' ', 1)\n",
        "        nid = int(nid)\n",
        "        \n",
        "        if nid == 1:\n",
        "            story = []\n",
        "        if '\\t' in line:\n",
        "            q, a, supporting = line.split('\\t')\n",
        "            if tokenize:\n",
        "                q = word_tokenizer(q)\n",
        "            substory = None\n",
        "            if only_supporting:\n",
        "                # Only select the related substory\n",
        "                supporting = map(int, supporting.split())\n",
        "                substory = [story[i - 1] for i in supporting]\n",
        "            else:\n",
        "                # Provide all the substories\n",
        "                substory = [x for x in story if x]\n",
        "            data.append((substory, q, a))\n",
        "            story.append('')\n",
        "        else:\n",
        "            if tokenize:\n",
        "                sent = word_tokenizer(line)\n",
        "            else:\n",
        "                sent = line\n",
        "            story.append(sent)\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwkiTJYRJvPe"
      },
      "source": [
        "Now we need to take proper structure of the data: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBc_rzF-rKjT"
      },
      "outputs": [],
      "source": [
        "def get_stories(f, only_supporting=False, max_length=None, tokenize=True):\n",
        "    data = parse_stories(f.readlines(), only_supporting=only_supporting, tokenize=tokenize)\n",
        "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
        "    data = [(story[0]+story[1], q, answer) for story, q, answer in data if not max_length or len(flatten(story)) < max_length]\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FivvTCc8J-GW"
      },
      "source": [
        "Here we need to make the vectors of stories, questions and answers. its too easy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzEnmDN_rKjW"
      },
      "outputs": [],
      "source": [
        "def vectorize_stories(data, word_idx, story_maxlen, query_maxlen):\n",
        "  \n",
        "    ########################################\n",
        "    #     Put your implementation here     #\n",
        "    ########################################\n",
        "    inputs_train = []\n",
        "    queries_train = []\n",
        "    answers_train = []\n",
        "\n",
        "    for d in data:\n",
        "      story, query, answer = d\n",
        "      \n",
        "      story_vec = np.zeros(story_maxlen)\n",
        "      for i in range(len(story)):\n",
        "        story_vec[i] = word_idx[story[i]]\n",
        "      inputs_train.append(np.array(story_vec))\n",
        "\n",
        "      query_vec = np.zeros(query_maxlen)\n",
        "      for i in range(len(query)):\n",
        "        query_vec[i] = word_idx[query[i]]\n",
        "      queries_train.append(query_vec)\n",
        "      \n",
        "      ans_vec = np.zeros(len(word_idx) + 1)\n",
        "      ans_num = word_idx[answer]\n",
        "      ans_vec[ans_num] = 1\n",
        "      answers_train.append(ans_vec)\n",
        "      \n",
        "    return np.array(inputs_train), np.array(queries_train), np.array(answers_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B77myra2ZJYK"
      },
      "source": [
        "Its time to extract stories from the dataset, then pass them to the defined functions for parsing and make it usable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Akcwoo3frKjj"
      },
      "outputs": [],
      "source": [
        "train_stories = get_stories(open(train_file_path), tokenize=True)\n",
        "test_stories = get_stories(open(test_file_path), tokenize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyiMaVRirKjm",
        "outputId": "4f43ee71-70e5-47dd-eb42-a300cc9e91eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "len(train_stories), len(test_stories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpXH9iYQrKjq"
      },
      "source": [
        "## 1.3 Check our helper functions and prepare the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29110FTDrKjr"
      },
      "outputs": [],
      "source": [
        "vocab = set()\n",
        "for story, q, answer in train_stories + test_stories:\n",
        "    vocab |= set(story + q + [answer])\n",
        "vocab = sorted(vocab)\n",
        "\n",
        "# Reserve 0 for masking via pad_sequences\n",
        "vocab_size = len(vocab) + 1\n",
        "story_maxlen = max(map(len, (x for x, _, _ in train_stories + test_stories)))\n",
        "query_maxlen = max(map(len, (x for _, x, _ in train_stories + test_stories)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PopB46hnrKju",
        "outputId": "b6f0c16b-d6f5-4536-8498-35e76a5a439f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "story_maxlen, query_maxlen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-G22KfxrKjy",
        "outputId": "727c98ca-1c40-47f8-b82b-330a00627051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Vocab size: 22 unique words\n",
            "Story max length: 14 words\n",
            "Query max length: 4 words\n",
            "Number of training stories: 10000\n",
            "Number of test stories: 1000\n",
            "-\n",
            "Here's what a \"story\" tuple looks like (input, query, answer):\n",
            "(['Mary', 'moved', 'to', 'the', 'bathroom', '.', 'John', 'went', 'to', 'the', 'hallway', '.'], ['Where', 'is', 'Mary', '?'], 'bathroom')\n",
            "-\n",
            "Vectorizing the word sequences...\n"
          ]
        }
      ],
      "source": [
        "print('-')\n",
        "print('Vocab size:', vocab_size, 'unique words')\n",
        "print('Story max length:', story_maxlen, 'words')\n",
        "print('Query max length:', query_maxlen, 'words')\n",
        "print('Number of training stories:', len(train_stories))\n",
        "print('Number of test stories:', len(test_stories))\n",
        "print('-')\n",
        "print('Here\\'s what a \"story\" tuple looks like (input, query, answer):')\n",
        "print(train_stories[0])\n",
        "print('-')\n",
        "print('Vectorizing the word sequences...')\n",
        "\n",
        "word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n",
        "idx_word = dict((i+1, c) for i,c in enumerate(vocab))\n",
        "inputs_train, queries_train, answers_train = vectorize_stories(train_stories,\n",
        "                                                               word_idx,\n",
        "                                                               story_maxlen,\n",
        "                                                               query_maxlen)\n",
        "inputs_test, queries_test, answers_test = vectorize_stories(test_stories,\n",
        "                                                            word_idx,\n",
        "                                                            story_maxlen,\n",
        "                                                            query_maxlen)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMnIXlTBrKj1",
        "outputId": "1d6b552d-c9a8-418c-f9a8-dffe60cc3474"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 14), (10000, 4), (10000, 22))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "inputs_train.shape, queries_train.shape, answers_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4lNOEBkrKj5",
        "outputId": "6c82fa5b-7c33-43f8-f98f-f9a44e291e26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "inputs: integer tensor of shape (samples, max_length)\n",
            "inputs_train shape: (10000, 14)\n",
            "inputs_test shape: (1000, 14)\n",
            "-\n",
            "queries: integer tensor of shape (samples, max_length)\n",
            "queries_train shape: (10000, 4)\n",
            "queries_test shape: (1000, 4)\n",
            "-\n",
            "answers: binary (1 or 0) tensor of shape (samples, vocab_size)\n",
            "answers_train shape: (10000, 22)\n",
            "answers_test shape: (1000, 22)\n",
            "-\n",
            "Compiling...\n"
          ]
        }
      ],
      "source": [
        "print('-')\n",
        "print('inputs: integer tensor of shape (samples, max_length)')\n",
        "print('inputs_train shape:', inputs_train.shape)\n",
        "print('inputs_test shape:', inputs_test.shape)\n",
        "print('-')\n",
        "print('queries: integer tensor of shape (samples, max_length)')\n",
        "print('queries_train shape:', queries_train.shape)\n",
        "print('queries_test shape:', queries_test.shape)\n",
        "print('-')\n",
        "print('answers: binary (1 or 0) tensor of shape (samples, vocab_size)')\n",
        "print('answers_train shape:', answers_train.shape)\n",
        "print('answers_test shape:', answers_test.shape)\n",
        "print('-')\n",
        "print('Compiling...')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvyawLqgfz_N"
      },
      "source": [
        "In this part you should implement 2 functions which illustrate the procedure of learning, Loss and Accuracy. These functions take two inputs: \n",
        "* The history of your designed model \n",
        "* Proper title for describing the plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8Ya5e3e3OWG"
      },
      "outputs": [],
      "source": [
        "def plot_acc(history, title):\n",
        "  \n",
        "  # This function should show not only the plot of accuracy on training and validation set\n",
        "  # but also it should show the maximum value of accuracy with its related epoch.\n",
        "  ########################################\n",
        "  #     Put your implementation here     #\n",
        "  ########################################\n",
        "  plt.plot(history.history['accuracy'],label=\"train_accuracy\")\n",
        "  plt.plot(history.history['val_accuracy'],label=\"validation_accuracy\")\n",
        "  plt.xlabel(\"epoch\")\n",
        "  plt.ylabel(title)\n",
        "  plt.legend()\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pA9BBcEP3Hym"
      },
      "outputs": [],
      "source": [
        "def plot_loss(history, title):\n",
        "  \n",
        "  # This function should show not only the plot of loss on training and validation set\n",
        "  # but also it should show the minimum value of loss with its related epoch.\n",
        "  ########################################\n",
        "  #     Put your implementation here     #\n",
        "  ########################################\n",
        "  plt.plot(history.history['loss'],label=\"train_loss\")\n",
        "  plt.plot(history.history['val_loss'],label=\"validation_loss\")\n",
        "  plt.xlabel(\"epoch\")\n",
        "  plt.ylabel(title)\n",
        "  plt.legend()\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMxMeM78xBT8"
      },
      "source": [
        "Define model's hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6-mw90LrKj9"
      },
      "outputs": [],
      "source": [
        "train_epochs = 10\n",
        "batch_size = 32\n",
        "lstm_size = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G5X8ksgrKkA"
      },
      "source": [
        "## 1.4 Implementstion:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayB5NMoI-Sh-"
      },
      "source": [
        "Let's build the model. You should use Keras framework. The summary and outview of the right model is saved in the next cells to help you create the proper model faster.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UNREQ9rrKkB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6f7353a-1266-442f-d239-74f8bc334fed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input sequence: KerasTensor(type_spec=TensorSpec(shape=(None, 14), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\")\n",
            "Question: KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\")\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Embedding, Dot, Activation, Permute, Concatenate, LSTM, Dropout, Dense, Add\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "# define the model: \n",
        "input_sequence = tf.keras.layers.Input((story_maxlen,))\n",
        "question = tf.keras.layers.Input((query_maxlen,))\n",
        "\n",
        "print('Input sequence:', input_sequence)\n",
        "print('Question:', question)\n",
        "\n",
        "########################################\n",
        "#     Put your implementation here     #\n",
        "########################################\n",
        "sequential1 = Sequential([Embedding(vocab_size, 64)])(input_sequence)\n",
        "sequential2 = Sequential([Embedding(vocab_size, 4)])(input_sequence)\n",
        "sequential3 = Sequential([Embedding(vocab_size, 64)])(question)\n",
        "dot = Dot(axes=(2, 2))([sequential1, sequential3])\n",
        "activation = Activation('relu')(dot)\n",
        "add = Add()([activation, sequential2])\n",
        "permute = Permute((2, 1))(add)\n",
        "concat = Concatenate()([permute, sequential3])\n",
        "lstm = LSTM(lstm_size)(concat)\n",
        "dropout = Dropout(0.1)(lstm)\n",
        "dense = Dense(vocab_size)(dropout)\n",
        "answer = Activation('softmax')(dense)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUvfDiLkrKkF"
      },
      "outputs": [],
      "source": [
        "# build the final model\n",
        "model = tf.keras.models.Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFqPorzN_9Lv"
      },
      "source": [
        "The model architecture should look like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aX6c1qWQ0iMX",
        "outputId": "e03a6935-f273-4958-bca3-d37d8ecc1972"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"737pt\" viewBox=\"0.00 0.00 905.00 885.00\" width=\"754pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(.8333 .8333) rotate(0) translate(4 881)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-881 901,-881 901,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139672945679120 -->\n<g class=\"node\" id=\"node1\">\n<title>139672945679120</title>\n<polygon fill=\"none\" points=\"121,-830.5 121,-876.5 410,-876.5 410,-830.5 121,-830.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152\" y=\"-849.8\">input_3</text>\n<polyline fill=\"none\" points=\"183,-830.5 183,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"223\" y=\"-849.8\">InputLayer</text>\n<polyline fill=\"none\" points=\"263,-830.5 263,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292\" y=\"-861.3\">input:</text>\n<polyline fill=\"none\" points=\"263,-853.5 321,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292\" y=\"-838.3\">output:</text>\n<polyline fill=\"none\" points=\"321,-830.5 321,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"365.5\" y=\"-861.3\">[(None, 14)]</text>\n<polyline fill=\"none\" points=\"321,-853.5 410,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"365.5\" y=\"-838.3\">[(None, 14)]</text>\n</g>\n<!-- 139672943974352 -->\n<g class=\"node\" id=\"node3\">\n<title>139672943974352</title>\n<polygon fill=\"none\" points=\"193,-747.5 193,-793.5 536,-793.5 536,-747.5 193,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"237.5\" y=\"-766.8\">sequential_3</text>\n<polyline fill=\"none\" points=\"282,-747.5 282,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"320.5\" y=\"-766.8\">Sequential</text>\n<polyline fill=\"none\" points=\"359,-747.5 359,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"388\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"359,-770.5 417,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"388\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"417,-747.5 417,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"476.5\" y=\"-778.3\">(None, None)</text>\n<polyline fill=\"none\" points=\"417,-770.5 536,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"476.5\" y=\"-755.3\">(None, None, 64)</text>\n</g>\n<!-- 139672945679120&#45;&gt;139672943974352 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139672945679120-&gt;139672943974352</title>\n<path d=\"M293.077,-830.3799C304.1407,-821.1043 317.0354,-810.2936 328.7999,-800.4304\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"331.313,-802.8908 336.7275,-793.784 326.8157,-797.5266 331.313,-802.8908\" stroke=\"#000000\"/>\n</g>\n<!-- 139672943988880 -->\n<g class=\"node\" id=\"node7\">\n<title>139672943988880</title>\n<polygon fill=\"none\" points=\"0,-664.5 0,-710.5 335,-710.5 335,-664.5 0,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"44.5\" y=\"-683.8\">sequential_4</text>\n<polyline fill=\"none\" points=\"89,-664.5 89,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127.5\" y=\"-683.8\">Sequential</text>\n<polyline fill=\"none\" points=\"166,-664.5 166,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"166,-687.5 224,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"224,-664.5 224,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279.5\" y=\"-695.3\">(None, None)</text>\n<polyline fill=\"none\" points=\"224,-687.5 335,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279.5\" y=\"-672.3\">(None, None, 4)</text>\n</g>\n<!-- 139672945679120&#45;&gt;139672943988880 -->\n<g class=\"edge\" id=\"edge6\">\n<title>139672945679120-&gt;139672943988880</title>\n<path d=\"M220.5803,-830.3156C206.5673,-820.902 192.4524,-808.7301 183.5,-794 170.2314,-772.168 166.5689,-743.3008 166.0379,-721.1283\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"169.537,-720.8287 166.0005,-710.8415 162.537,-720.8542 169.537,-720.8287\" stroke=\"#000000\"/>\n</g>\n<!-- 139672944000720 -->\n<g class=\"node\" id=\"node2\">\n<title>139672944000720</title>\n<polygon fill=\"none\" points=\"585,-830.5 585,-876.5 866,-876.5 866,-830.5 585,-830.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"616\" y=\"-849.8\">input_4</text>\n<polyline fill=\"none\" points=\"647,-830.5 647,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"687\" y=\"-849.8\">InputLayer</text>\n<polyline fill=\"none\" points=\"727,-830.5 727,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"756\" y=\"-861.3\">input:</text>\n<polyline fill=\"none\" points=\"727,-853.5 785,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"756\" y=\"-838.3\">output:</text>\n<polyline fill=\"none\" points=\"785,-830.5 785,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"825.5\" y=\"-861.3\">[(None, 4)]</text>\n<polyline fill=\"none\" points=\"785,-853.5 866,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"825.5\" y=\"-838.3\">[(None, 4)]</text>\n</g>\n<!-- 139672945530576 -->\n<g class=\"node\" id=\"node4\">\n<title>139672945530576</title>\n<polygon fill=\"none\" points=\"554,-747.5 554,-793.5 897,-793.5 897,-747.5 554,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"598.5\" y=\"-766.8\">sequential_5</text>\n<polyline fill=\"none\" points=\"643,-747.5 643,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"681.5\" y=\"-766.8\">Sequential</text>\n<polyline fill=\"none\" points=\"720,-747.5 720,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"749\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"720,-770.5 778,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"749\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"778,-747.5 778,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"837.5\" y=\"-778.3\">(None, None)</text>\n<polyline fill=\"none\" points=\"778,-770.5 897,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"837.5\" y=\"-755.3\">(None, None, 64)</text>\n</g>\n<!-- 139672944000720&#45;&gt;139672945530576 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139672944000720-&gt;139672945530576</title>\n<path d=\"M725.5,-830.3799C725.5,-822.1745 725.5,-812.7679 725.5,-803.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"729.0001,-803.784 725.5,-793.784 722.0001,-803.784 729.0001,-803.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139672945173584 -->\n<g class=\"node\" id=\"node5\">\n<title>139672945173584</title>\n<polygon fill=\"none\" points=\"353,-664.5 353,-710.5 696,-710.5 696,-664.5 353,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"378\" y=\"-683.8\">dot_1</text>\n<polyline fill=\"none\" points=\"403,-664.5 403,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"422\" y=\"-683.8\">Dot</text>\n<polyline fill=\"none\" points=\"441,-664.5 441,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"470\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"441,-687.5 499,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"470\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"499,-664.5 499,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"597.5\" y=\"-695.3\">[(None, 14, 64), (None, 4, 64)]</text>\n<polyline fill=\"none\" points=\"499,-687.5 696,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"597.5\" y=\"-672.3\">(None, 14, 4)</text>\n</g>\n<!-- 139672943974352&#45;&gt;139672945173584 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139672943974352-&gt;139672945173584</title>\n<path d=\"M409.0689,-747.3799C428.2333,-737.4384 450.7971,-725.7334 470.8678,-715.3217\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"472.6278,-718.3516 479.8929,-710.6399 469.4045,-712.1379 472.6278,-718.3516\" stroke=\"#000000\"/>\n</g>\n<!-- 139672945530576&#45;&gt;139672945173584 -->\n<g class=\"edge\" id=\"edge4\">\n<title>139672945530576-&gt;139672945173584</title>\n<path d=\"M669.7772,-747.4901C644.9434,-737.2353 615.5245,-725.0872 589.6772,-714.414\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"590.91,-711.1364 580.3312,-710.5547 588.2383,-717.6065 590.91,-711.1364\" stroke=\"#000000\"/>\n</g>\n<!-- 139672944016080 -->\n<g class=\"node\" id=\"node10\">\n<title>139672944016080</title>\n<polygon fill=\"none\" points=\"410,-332.5 410,-378.5 841,-378.5 841,-332.5 410,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"459\" y=\"-351.8\">concatenate_1</text>\n<polyline fill=\"none\" points=\"508,-332.5 508,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"551\" y=\"-351.8\">Concatenate</text>\n<polyline fill=\"none\" points=\"594,-332.5 594,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"623\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"594,-355.5 652,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"623\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"652,-332.5 652,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"746.5\" y=\"-363.3\">[(None, 4, 14), (None, 4, 64)]</text>\n<polyline fill=\"none\" points=\"652,-355.5 841,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"746.5\" y=\"-340.3\">(None, 4, 78)</text>\n</g>\n<!-- 139672945530576&#45;&gt;139672944016080 -->\n<g class=\"edge\" id=\"edge11\">\n<title>139672945530576-&gt;139672944016080</title>\n<path d=\"M725.2731,-747.4055C724.978,-715.3386 724.5,-655.5113 724.5,-604.5 724.5,-604.5 724.5,-604.5 724.5,-521.5 724.5,-472.3246 720.9075,-456.4833 694.5,-415 687.4623,-403.9446 677.7528,-393.8129 667.8379,-385.1651\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"669.8171,-382.259 659.8895,-378.5585 665.3426,-387.6422 669.8171,-382.259\" stroke=\"#000000\"/>\n</g>\n<!-- 139672944030032 -->\n<g class=\"node\" id=\"node6\">\n<title>139672944030032</title>\n<polygon fill=\"none\" points=\"366,-581.5 366,-627.5 683,-627.5 683,-581.5 366,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"409.5\" y=\"-600.8\">activation_2</text>\n<polyline fill=\"none\" points=\"453,-581.5 453,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"491.5\" y=\"-600.8\">Activation</text>\n<polyline fill=\"none\" points=\"530,-581.5 530,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"559\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"530,-604.5 588,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"559\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"588,-581.5 588,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"635.5\" y=\"-612.3\">(None, 14, 4)</text>\n<polyline fill=\"none\" points=\"588,-604.5 683,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"635.5\" y=\"-589.3\">(None, 14, 4)</text>\n</g>\n<!-- 139672945173584&#45;&gt;139672944030032 -->\n<g class=\"edge\" id=\"edge5\">\n<title>139672945173584-&gt;139672944030032</title>\n<path d=\"M524.5,-664.3799C524.5,-656.1745 524.5,-646.7679 524.5,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"528.0001,-637.784 524.5,-627.784 521.0001,-637.784 528.0001,-637.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139672944792784 -->\n<g class=\"node\" id=\"node8\">\n<title>139672944792784</title>\n<polygon fill=\"none\" points=\"353.5,-498.5 353.5,-544.5 695.5,-544.5 695.5,-498.5 353.5,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"380\" y=\"-517.8\">add_1</text>\n<polyline fill=\"none\" points=\"406.5,-498.5 406.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"427.5\" y=\"-517.8\">Add</text>\n<polyline fill=\"none\" points=\"448.5,-498.5 448.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"477.5\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"448.5,-521.5 506.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"477.5\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"506.5,-498.5 506.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"601\" y=\"-529.3\">[(None, 14, 4), (None, 14, 4)]</text>\n<polyline fill=\"none\" points=\"506.5,-521.5 695.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"601\" y=\"-506.3\">(None, 14, 4)</text>\n</g>\n<!-- 139672944030032&#45;&gt;139672944792784 -->\n<g class=\"edge\" id=\"edge7\">\n<title>139672944030032-&gt;139672944792784</title>\n<path d=\"M524.5,-581.3799C524.5,-573.1745 524.5,-563.7679 524.5,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"528.0001,-554.784 524.5,-544.784 521.0001,-554.784 528.0001,-554.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139672943988880&#45;&gt;139672944792784 -->\n<g class=\"edge\" id=\"edge8\">\n<title>139672943988880-&gt;139672944792784</title>\n<path d=\"M204.1582,-664.3259C241.5295,-641.3093 301.6435,-605.9437 356.5,-581 383.4597,-568.7412 413.7446,-557.3316 441.0994,-547.8499\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"442.3182,-551.1321 450.6427,-544.5783 440.0481,-544.5104 442.3182,-551.1321\" stroke=\"#000000\"/>\n</g>\n<!-- 139677253939408 -->\n<g class=\"node\" id=\"node9\">\n<title>139677253939408</title>\n<polygon fill=\"none\" points=\"390,-415.5 390,-461.5 685,-461.5 685,-415.5 390,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"429\" y=\"-434.8\">permute_1</text>\n<polyline fill=\"none\" points=\"468,-415.5 468,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"500\" y=\"-434.8\">Permute</text>\n<polyline fill=\"none\" points=\"532,-415.5 532,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"561\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"532,-438.5 590,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"561\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"590,-415.5 590,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"637.5\" y=\"-446.3\">(None, 14, 4)</text>\n<polyline fill=\"none\" points=\"590,-438.5 685,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"637.5\" y=\"-423.3\">(None, 4, 14)</text>\n</g>\n<!-- 139672944792784&#45;&gt;139677253939408 -->\n<g class=\"edge\" id=\"edge9\">\n<title>139672944792784-&gt;139677253939408</title>\n<path d=\"M528.1212,-498.3799C529.4064,-490.1745 530.8797,-480.7679 532.272,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"535.7635,-472.2052 533.8531,-461.784 528.8478,-471.1219 535.7635,-472.2052\" stroke=\"#000000\"/>\n</g>\n<!-- 139677253939408&#45;&gt;139672944016080 -->\n<g class=\"edge\" id=\"edge10\">\n<title>139677253939408-&gt;139672944016080</title>\n<path d=\"M562.0129,-415.3799C571.7527,-406.1935 583.089,-395.5013 593.4646,-385.7152\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"595.9401,-388.1916 600.8133,-378.784 591.1371,-383.0993 595.9401,-388.1916\" stroke=\"#000000\"/>\n</g>\n<!-- 139672944055824 -->\n<g class=\"node\" id=\"node11\">\n<title>139672944055824</title>\n<polygon fill=\"none\" points=\"493,-249.5 493,-295.5 758,-295.5 758,-249.5 493,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"521\" y=\"-268.8\">lstm_1</text>\n<polyline fill=\"none\" points=\"549,-249.5 549,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"577\" y=\"-268.8\">LSTM</text>\n<polyline fill=\"none\" points=\"605,-249.5 605,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"634\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"605,-272.5 663,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"634\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"663,-249.5 663,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"710.5\" y=\"-280.3\">(None, 4, 78)</text>\n<polyline fill=\"none\" points=\"663,-272.5 758,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"710.5\" y=\"-257.3\">(None, 32)</text>\n</g>\n<!-- 139672944016080&#45;&gt;139672944055824 -->\n<g class=\"edge\" id=\"edge12\">\n<title>139672944016080-&gt;139672944055824</title>\n<path d=\"M625.5,-332.3799C625.5,-324.1745 625.5,-314.7679 625.5,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"629.0001,-305.784 625.5,-295.784 622.0001,-305.784 629.0001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139672944074384 -->\n<g class=\"node\" id=\"node12\">\n<title>139672944074384</title>\n<polygon fill=\"none\" points=\"485.5,-166.5 485.5,-212.5 765.5,-212.5 765.5,-166.5 485.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"524\" y=\"-185.8\">dropout_1</text>\n<polyline fill=\"none\" points=\"562.5,-166.5 562.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"595\" y=\"-185.8\">Dropout</text>\n<polyline fill=\"none\" points=\"627.5,-166.5 627.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"656.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"627.5,-189.5 685.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"656.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"685.5,-166.5 685.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"725.5\" y=\"-197.3\">(None, 32)</text>\n<polyline fill=\"none\" points=\"685.5,-189.5 765.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"725.5\" y=\"-174.3\">(None, 32)</text>\n</g>\n<!-- 139672944055824&#45;&gt;139672944074384 -->\n<g class=\"edge\" id=\"edge13\">\n<title>139672944055824-&gt;139672944074384</title>\n<path d=\"M625.5,-249.3799C625.5,-241.1745 625.5,-231.7679 625.5,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"629.0001,-222.784 625.5,-212.784 622.0001,-222.784 629.0001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139672944063184 -->\n<g class=\"node\" id=\"node13\">\n<title>139672944063184</title>\n<polygon fill=\"none\" points=\"498.5,-83.5 498.5,-129.5 752.5,-129.5 752.5,-83.5 498.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530.5\" y=\"-102.8\">dense_1</text>\n<polyline fill=\"none\" points=\"562.5,-83.5 562.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"588.5\" y=\"-102.8\">Dense</text>\n<polyline fill=\"none\" points=\"614.5,-83.5 614.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"643.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"614.5,-106.5 672.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"643.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"672.5,-83.5 672.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"712.5\" y=\"-114.3\">(None, 32)</text>\n<polyline fill=\"none\" points=\"672.5,-106.5 752.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"712.5\" y=\"-91.3\">(None, 22)</text>\n</g>\n<!-- 139672944074384&#45;&gt;139672944063184 -->\n<g class=\"edge\" id=\"edge14\">\n<title>139672944074384-&gt;139672944063184</title>\n<path d=\"M625.5,-166.3799C625.5,-158.1745 625.5,-148.7679 625.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"629.0001,-139.784 625.5,-129.784 622.0001,-139.784 629.0001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139672944018640 -->\n<g class=\"node\" id=\"node14\">\n<title>139672944018640</title>\n<polygon fill=\"none\" points=\"474.5,-.5 474.5,-46.5 776.5,-46.5 776.5,-.5 474.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"518\" y=\"-19.8\">activation_3</text>\n<polyline fill=\"none\" points=\"561.5,-.5 561.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"600\" y=\"-19.8\">Activation</text>\n<polyline fill=\"none\" points=\"638.5,-.5 638.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"667.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"638.5,-23.5 696.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"667.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"696.5,-.5 696.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"736.5\" y=\"-31.3\">(None, 22)</text>\n<polyline fill=\"none\" points=\"696.5,-23.5 776.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"736.5\" y=\"-8.3\">(None, 22)</text>\n</g>\n<!-- 139672944063184&#45;&gt;139672944018640 -->\n<g class=\"edge\" id=\"edge15\">\n<title>139672944063184-&gt;139672944018640</title>\n<path d=\"M625.5,-83.3799C625.5,-75.1745 625.5,-65.7679 625.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"629.0001,-56.784 625.5,-46.784 622.0001,-56.784 629.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "from IPython.display import SVG\n",
        "\n",
        "SVG(tf.keras.utils.model_to_dot(model,show_shapes= True, show_layer_names=True, dpi=60).create(prog='dot', format='svg'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxK-MxYMrKkI"
      },
      "source": [
        "Model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjEgTL9LrKkJ",
        "outputId": "8f639653-9b79-48be-a0a3-23460c8a7dbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 14)]         0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " sequential_3 (Sequential)      (None, None, 64)     1408        ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " sequential_5 (Sequential)      (None, None, 64)     1408        ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dot_1 (Dot)                    (None, 14, 4)        0           ['sequential_3[0][0]',           \n",
            "                                                                  'sequential_5[0][0]']           \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 14, 4)        0           ['dot_1[0][0]']                  \n",
            "                                                                                                  \n",
            " sequential_4 (Sequential)      (None, None, 4)      88          ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 14, 4)        0           ['activation_2[0][0]',           \n",
            "                                                                  'sequential_4[0][0]']           \n",
            "                                                                                                  \n",
            " permute_1 (Permute)            (None, 4, 14)        0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 4, 78)        0           ['permute_1[0][0]',              \n",
            "                                                                  'sequential_5[0][0]']           \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  (None, 32)           14208       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 32)           0           ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 22)           726         ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 22)           0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 17,838\n",
            "Trainable params: 17,838\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tnbz5YJrKkQ"
      },
      "source": [
        "## 1.5 Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_bUUHq-A8Us"
      },
      "source": [
        "In this section we start the training procedure with fitting the data to the designed model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3sOGkotZKmk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f8906ab5-4e6e-4c65-f37d-4c7d01a3c8db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\r  1/313 [..............................] - ETA: 14s - loss: 1.7716 - accuracy: 0.1875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4527: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 17s 55ms/step - loss: 1.8026 - accuracy: 0.1676 - val_loss: 1.7933 - val_accuracy: 0.1920\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 18s 57ms/step - loss: 1.7886 - accuracy: 0.1861 - val_loss: 1.7713 - val_accuracy: 0.2350\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 17s 53ms/step - loss: 1.7780 - accuracy: 0.2113 - val_loss: 1.7636 - val_accuracy: 0.2560\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 17s 53ms/step - loss: 1.7699 - accuracy: 0.2285 - val_loss: 1.7489 - val_accuracy: 0.2780\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 17s 55ms/step - loss: 1.7634 - accuracy: 0.2412 - val_loss: 1.7427 - val_accuracy: 0.2730\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 17s 53ms/step - loss: 1.7601 - accuracy: 0.2458 - val_loss: 1.7392 - val_accuracy: 0.2890\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 17s 54ms/step - loss: 1.7571 - accuracy: 0.2507 - val_loss: 1.7361 - val_accuracy: 0.2900\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 17s 55ms/step - loss: 1.7547 - accuracy: 0.2520 - val_loss: 1.7357 - val_accuracy: 0.2870\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 17s 54ms/step - loss: 1.7518 - accuracy: 0.2542 - val_loss: 1.7313 - val_accuracy: 0.2990\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 16s 53ms/step - loss: 1.7498 - accuracy: 0.2615 - val_loss: 1.7244 - val_accuracy: 0.2840\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        }
      ],
      "source": [
        "history = model.fit([inputs_train, queries_train], answers_train, batch_size, train_epochs,\n",
        "          validation_data=([inputs_test, queries_test], answers_test))\n",
        "\n",
        "plot_loss(history,\"Loss\")\n",
        "plot_acc(history,\"Accuracy\")\n",
        "\n",
        "model.save('model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXxhXOvcrKkV"
      },
      "source": [
        "## 1.6 Testing and Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciBt077dEBLd"
      },
      "source": [
        "Now we need to actually make predictions and check the performance of our trained model with some examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4b3f5-arKkW",
        "outputId": "596d99f8-2c7e-40f8-a7c1-019fecf163d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4527: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "John travelled to the hallway . Mary journeyed to the bathroom . Where is John ? | Prediction: bathroom | Ground Truth: hallway\n",
            "-----------------------------------------------------------------------------------------\n",
            "John travelled to the hallway . Mary journeyed to the bathroom . Where is Sandra ? | Prediction: hallway | Ground Truth: kitchen\n",
            "-----------------------------------------------------------------------------------------\n",
            "John travelled to the hallway . Mary journeyed to the bathroom . Where is Sandra ? | Prediction: hallway | Ground Truth: kitchen\n",
            "-----------------------------------------------------------------------------------------\n",
            "Sandra travelled to the kitchen . Sandra travelled to the hallway . Where is Sandra ? | Prediction: hallway | Ground Truth: garden\n",
            "-----------------------------------------------------------------------------------------\n",
            "Sandra travelled to the kitchen . Sandra travelled to the hallway . Where is Sandra ? | Prediction: hallway | Ground Truth: office\n",
            "-----------------------------------------------------------------------------------------\n",
            "John travelled to the office . Mary journeyed to the kitchen . Where is Mary ? | Prediction: kitchen | Ground Truth: kitchen\n",
            "-----------------------------------------------------------------------------------------\n",
            "John travelled to the office . Mary journeyed to the kitchen . Where is Daniel ? | Prediction: kitchen | Ground Truth: office\n",
            "-----------------------------------------------------------------------------------------\n",
            "John travelled to the office . Mary journeyed to the kitchen . Where is Mary ? | Prediction: kitchen | Ground Truth: bedroom\n",
            "-----------------------------------------------------------------------------------------\n",
            "John moved to the hallway . John journeyed to the kitchen . Where is John ? | Prediction: kitchen | Ground Truth: garden\n",
            "-----------------------------------------------------------------------------------------\n",
            "John moved to the hallway . John journeyed to the kitchen . Where is Daniel ? | Prediction: kitchen | Ground Truth: office\n",
            "-----------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for i in range(0,10):\n",
        "    current_inp = test_stories[2*i]\n",
        "    current_story, current_query, current_answer = vectorize_stories([current_inp], word_idx, story_maxlen, query_maxlen)\n",
        "    current_prediction = model.predict([current_story, current_query])\n",
        "    current_prediction = idx_word[np.argmax(current_prediction)]\n",
        "    print(' '.join(current_inp[0]), ' '.join(current_inp[1]), '| Prediction:', current_prediction, '| Ground Truth:', current_inp[2])\n",
        "    print(\"-----------------------------------------------------------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "DWGbl4PdrKka"
      },
      "source": [
        "## 1.7 Custom Inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJUI2SIXEV4x"
      },
      "source": [
        "You can even write your example and test it with your model to see how powerful it is:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UT83MJ8yrKkb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "outputId": "498066fe-ea16-4560-9f73-146e9b4c3ec3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------------------------------------\n",
            "Custom User Queries (Make sure there are spaces before each word)\n",
            "-------------------------------------------------------------------------------------------\n",
            "Please input a story\n",
            "Sandra travelled to the office . John journeyed to the garden .\n",
            "Please input a query\n",
            "Where is John ?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4527: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result\n",
            "Sandra travelled to the office . John journeyed to the garden . Where is John ? | Prediction: garden\n",
            "-------------------------------------------------------------------------------------------\n",
            "Please input a story\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \"\"\"\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-cd5b1d8fbfdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-------------------------------------------------------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please input a story'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0muser_story_inp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please input a query'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0muser_query_inp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "print('-------------------------------------------------------------------------------------------')\n",
        "print('Custom User Queries (Make sure there are spaces before each word)')\n",
        "while 1:\n",
        "    print('-------------------------------------------------------------------------------------------')\n",
        "    print('Please input a story')\n",
        "    user_story_inp = input().split(' ')\n",
        "    print('Please input a query')\n",
        "    user_query_inp = input().split(' ')\n",
        "    user_story, user_query, user_ans = vectorize_stories([[user_story_inp, user_query_inp, '.']], word_idx, story_maxlen, query_maxlen)\n",
        "    user_prediction = model.predict([user_story, user_query])\n",
        "    user_prediction = idx_word[np.argmax(user_prediction)]\n",
        "    print('Result')\n",
        "    print(' '.join(user_story_inp), ' '.join(user_query_inp), '| Prediction:', user_prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "id1unEEQrKkf"
      },
      "outputs": [],
      "source": [
        "# some examples:\n",
        "# Mary went to the bathroom . John moved to the hallway . Mary travelled to the office . # Where is Mary ?\n",
        "# Sandra travelled to the office . John journeyed to the garden ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtYRcM2KE4te"
      },
      "source": [
        "As you understood how the model trained, please tell us about the pros and cons of the proposed model. How can we improve it if we want to use it in realistic task ? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9NiIbN5F7zb"
      },
      "source": [
        "$\\color{red}{\\text{Write your answer in document}}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFKXfqrgQfQm"
      },
      "source": [
        "#  2. Hands on SSL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WP9j6u6hADR"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7UbcqmKUZ1q"
      },
      "source": [
        "## 2.1 prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDOwLbCAjENO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "370cf731-0900-4b80-8aa1-6f8dc35d49be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 5s 0us/step\n",
            "170508288/170498071 [==============================] - 5s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GMQmFwajGW4"
      },
      "outputs": [],
      "source": [
        "unlabeld_index = np.ones(y_train.shape, np.bool)\n",
        "\n",
        "N = 20\n",
        "for i in range(10):\n",
        "  idx = np.where(y_train == i)[0][:N]\n",
        "  unlabeld_index[idx] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBwOJ5sJjJOm"
      },
      "outputs": [],
      "source": [
        "x_unlabeld = x_train[np.where(unlabeld_index)[0], ...]\n",
        "\n",
        "x_train = x_train[np.where(~unlabeld_index)[0], ...]\n",
        "y_train = y_train[np.where(~unlabeld_index)[0], ...]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4R5nnKejLF2",
        "outputId": "10aa6ff6-ad8e-4642-c1d6-d9e5638e688a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.051293306\n",
            "0.0\n",
            "0.0\n"
          ]
        }
      ],
      "source": [
        "# examples of categorical crossentropy\n",
        "cce = keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "# a labeled data from the second class\n",
        "y_true = [[0, 1, 0, 0]]\n",
        "y_pred = [[0.05, 0.95, 0, 0]]\n",
        "print(cce(y_true, y_pred).numpy())\n",
        "\n",
        "# an ulabeled data\n",
        "y_true = [[0, 0, 0, 0]]\n",
        "y_pred = [[0.05, 0.95, 0, 0]]\n",
        "print(cce(y_true, y_pred).numpy())\n",
        "\n",
        "# another ulabeled data\n",
        "y_true = [[0, 0, 0, 0]]\n",
        "y_pred = [[0.1, 0.4, 0.3, 0.2]]\n",
        "print(cce(y_true, y_pred).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jy8IRxwpGZh",
        "outputId": "04b66660-0dbb-4df7-e7f4-540daab754ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(49800, 32, 32, 3)\n",
            "(200, 32, 32, 3)\n",
            "(200, 1)\n"
          ]
        }
      ],
      "source": [
        "print(x_unlabeld.shape)\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-OA4dSPq0D4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# preprocess dataset\n",
        "x_unlabeld_normalized = np.divide(x_unlabeld.astype('float32'), 255)\n",
        "x_train_normalized = np.divide(x_train.astype('float32'), 255)\n",
        "y_train_onehot = to_categorical(y_train, num_classes=10)\n",
        "\n",
        "# preprocess trainset\n",
        "x_test_normalized = np.divide(x_test.astype('float32'), 255)\n",
        "y_test_onehot = to_categorical(y_test, num_classes=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxIymD4DyNSg",
        "outputId": "1de99bdf-f4af-4093-fa3c-9f5c01e34b5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 10)\n",
            "(10000, 10)\n"
          ]
        }
      ],
      "source": [
        "print(y_train_onehot.shape)\n",
        "print(y_test_onehot.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPDQ6h0ksIbA"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "def convolutional(p):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(p))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(p))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(p))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8pjGoiiumPo",
        "outputId": "0883a103-7212-4bfe-fbf1-f82179e3c62e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               262272    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 552,362\n",
            "Trainable params: 551,466\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model1 = convolutional(0.2)\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model1.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0YoRGstukqX"
      },
      "outputs": [],
      "source": [
        "opt = Adam(learning_rate=0.01)\n",
        "model1.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYJgOXfZxGEO",
        "outputId": "32b1ab24-b21e-446d-fe59-40c03fb30c4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 22s 7s/step - loss: 9.1873 - accuracy: 0.1600 - val_loss: 2402.4680 - val_accuracy: 0.0913\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 23s 7s/step - loss: 5.9166 - accuracy: 0.2000 - val_loss: 2992.3362 - val_accuracy: 0.1283\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 23s 8s/step - loss: 5.9463 - accuracy: 0.3150 - val_loss: 5952.2778 - val_accuracy: 0.1007\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 22s 7s/step - loss: 4.4410 - accuracy: 0.3350 - val_loss: 5850.2920 - val_accuracy: 0.0976\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 22s 7s/step - loss: 4.5020 - accuracy: 0.3000 - val_loss: 3503.3760 - val_accuracy: 0.0993\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 22s 7s/step - loss: 3.8864 - accuracy: 0.3250 - val_loss: 1447.0992 - val_accuracy: 0.1235\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 22s 7s/step - loss: 3.0249 - accuracy: 0.3850 - val_loss: 457.3521 - val_accuracy: 0.1105\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 22s 7s/step - loss: 3.3325 - accuracy: 0.3650 - val_loss: 221.2388 - val_accuracy: 0.1237\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 2.5871 - accuracy: 0.3550 - val_loss: 233.8309 - val_accuracy: 0.1255\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 22s 7s/step - loss: 2.2392 - accuracy: 0.3900 - val_loss: 170.2009 - val_accuracy: 0.1293\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 1.6362 - accuracy: 0.4550 - val_loss: 94.7551 - val_accuracy: 0.1601\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 1.6398 - accuracy: 0.4850 - val_loss: 98.1842 - val_accuracy: 0.1432\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 1.5910 - accuracy: 0.5350 - val_loss: 79.6656 - val_accuracy: 0.1343\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 22s 7s/step - loss: 1.3932 - accuracy: 0.5800 - val_loss: 52.6287 - val_accuracy: 0.1498\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 22s 7s/step - loss: 2.0451 - accuracy: 0.4850 - val_loss: 54.7408 - val_accuracy: 0.1176\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 2.1911 - accuracy: 0.5100 - val_loss: 60.8361 - val_accuracy: 0.1461\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 1.6289 - accuracy: 0.5450 - val_loss: 86.4782 - val_accuracy: 0.1100\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 1.4461 - accuracy: 0.5700 - val_loss: 53.1840 - val_accuracy: 0.1272\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 1.4280 - accuracy: 0.5900 - val_loss: 41.6968 - val_accuracy: 0.1416\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 1.2310 - accuracy: 0.5800 - val_loss: 58.7458 - val_accuracy: 0.1374\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 1.4066 - accuracy: 0.5950 - val_loss: 59.0705 - val_accuracy: 0.1432\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 1.3371 - accuracy: 0.6100 - val_loss: 45.6180 - val_accuracy: 0.1449\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 1.2189 - accuracy: 0.6450 - val_loss: 30.1046 - val_accuracy: 0.1467\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 1.0165 - accuracy: 0.6550 - val_loss: 21.5247 - val_accuracy: 0.1566\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.9316 - accuracy: 0.6950 - val_loss: 14.5729 - val_accuracy: 0.1786\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.9997 - accuracy: 0.6300 - val_loss: 15.1546 - val_accuracy: 0.1813\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.8849 - accuracy: 0.7000 - val_loss: 18.9974 - val_accuracy: 0.1737\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.8594 - accuracy: 0.7000 - val_loss: 18.2497 - val_accuracy: 0.1644\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.8081 - accuracy: 0.6750 - val_loss: 13.2827 - val_accuracy: 0.1610\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.9890 - accuracy: 0.6650 - val_loss: 11.1884 - val_accuracy: 0.1702\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.7499 - accuracy: 0.7350 - val_loss: 11.2526 - val_accuracy: 0.1881\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.8438 - accuracy: 0.7150 - val_loss: 12.1685 - val_accuracy: 0.1738\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.9747 - accuracy: 0.6700 - val_loss: 14.0916 - val_accuracy: 0.1525\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 20s 7s/step - loss: 0.8104 - accuracy: 0.7250 - val_loss: 15.0741 - val_accuracy: 0.1609\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.6709 - accuracy: 0.7700 - val_loss: 15.4125 - val_accuracy: 0.1506\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.8740 - accuracy: 0.7250 - val_loss: 12.3687 - val_accuracy: 0.1776\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 20s 7s/step - loss: 0.7499 - accuracy: 0.7350 - val_loss: 11.0581 - val_accuracy: 0.1914\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.7133 - accuracy: 0.7550 - val_loss: 10.2012 - val_accuracy: 0.1790\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.5733 - accuracy: 0.7900 - val_loss: 9.7685 - val_accuracy: 0.1750\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 20s 7s/step - loss: 0.7976 - accuracy: 0.7150 - val_loss: 9.7577 - val_accuracy: 0.1787\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.5589 - accuracy: 0.7950 - val_loss: 7.3256 - val_accuracy: 0.1772\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.5531 - accuracy: 0.8200 - val_loss: 5.5438 - val_accuracy: 0.1854\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.6869 - accuracy: 0.7750 - val_loss: 6.6163 - val_accuracy: 0.2018\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.7278 - accuracy: 0.7800 - val_loss: 7.8963 - val_accuracy: 0.1960\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 20s 7s/step - loss: 1.1100 - accuracy: 0.7200 - val_loss: 6.2382 - val_accuracy: 0.1743\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.8857 - accuracy: 0.6900 - val_loss: 7.0523 - val_accuracy: 0.1767\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 20s 7s/step - loss: 0.9949 - accuracy: 0.7450 - val_loss: 10.6246 - val_accuracy: 0.1656\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 20s 7s/step - loss: 1.0079 - accuracy: 0.7250 - val_loss: 8.3869 - val_accuracy: 0.1668\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 20s 7s/step - loss: 0.5878 - accuracy: 0.8100 - val_loss: 8.5530 - val_accuracy: 0.1839\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 20s 7s/step - loss: 0.5795 - accuracy: 0.7850 - val_loss: 7.1271 - val_accuracy: 0.1937\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 20s 7s/step - loss: 0.6088 - accuracy: 0.7950 - val_loss: 7.1719 - val_accuracy: 0.1805\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 20s 7s/step - loss: 0.5063 - accuracy: 0.8150 - val_loss: 7.9903 - val_accuracy: 0.1734\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 20s 7s/step - loss: 0.4899 - accuracy: 0.8350 - val_loss: 8.1691 - val_accuracy: 0.1841\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 20s 7s/step - loss: 0.4644 - accuracy: 0.8550 - val_loss: 9.6497 - val_accuracy: 0.1641\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 20s 7s/step - loss: 0.5821 - accuracy: 0.8450 - val_loss: 10.3443 - val_accuracy: 0.1642\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 20s 7s/step - loss: 0.5124 - accuracy: 0.8150 - val_loss: 9.8218 - val_accuracy: 0.1879\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.4204 - accuracy: 0.8450 - val_loss: 9.5166 - val_accuracy: 0.1961\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 20s 7s/step - loss: 0.3446 - accuracy: 0.8950 - val_loss: 8.5179 - val_accuracy: 0.1989\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.2809 - accuracy: 0.9000 - val_loss: 8.6122 - val_accuracy: 0.1859\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.4341 - accuracy: 0.8650 - val_loss: 8.5804 - val_accuracy: 0.1965\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 23s 8s/step - loss: 0.3523 - accuracy: 0.8700 - val_loss: 7.0312 - val_accuracy: 0.2105\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.4046 - accuracy: 0.8450 - val_loss: 6.2200 - val_accuracy: 0.2156\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.3038 - accuracy: 0.8900 - val_loss: 6.3407 - val_accuracy: 0.2220\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 20s 7s/step - loss: 0.3071 - accuracy: 0.9150 - val_loss: 6.5509 - val_accuracy: 0.2294\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 20s 7s/step - loss: 0.3234 - accuracy: 0.8900 - val_loss: 6.4203 - val_accuracy: 0.2306\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 20s 7s/step - loss: 0.3965 - accuracy: 0.8600 - val_loss: 7.2288 - val_accuracy: 0.2029\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.3713 - accuracy: 0.8700 - val_loss: 6.6355 - val_accuracy: 0.2198\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.3141 - accuracy: 0.8950 - val_loss: 5.8224 - val_accuracy: 0.2344\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.2349 - accuracy: 0.9300 - val_loss: 5.6117 - val_accuracy: 0.2396\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.3936 - accuracy: 0.9200 - val_loss: 5.4658 - val_accuracy: 0.2275\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.2778 - accuracy: 0.9100 - val_loss: 5.8189 - val_accuracy: 0.1968\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.7949 - accuracy: 0.8250 - val_loss: 5.5225 - val_accuracy: 0.2016\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.8003 - accuracy: 0.7800 - val_loss: 6.0236 - val_accuracy: 0.2001\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.6338 - accuracy: 0.8550 - val_loss: 6.6753 - val_accuracy: 0.2259\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.3994 - accuracy: 0.9150 - val_loss: 7.7057 - val_accuracy: 0.2253\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.4314 - accuracy: 0.8900 - val_loss: 7.5989 - val_accuracy: 0.2169\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.3561 - accuracy: 0.8850 - val_loss: 7.2602 - val_accuracy: 0.2168\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.3352 - accuracy: 0.9050 - val_loss: 7.5365 - val_accuracy: 0.2114\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.3852 - accuracy: 0.8550 - val_loss: 7.5145 - val_accuracy: 0.2053\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.2961 - accuracy: 0.8900 - val_loss: 6.8383 - val_accuracy: 0.1916\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.3609 - accuracy: 0.8900 - val_loss: 6.7615 - val_accuracy: 0.2004\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.3355 - accuracy: 0.8800 - val_loss: 6.2376 - val_accuracy: 0.2113\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.2731 - accuracy: 0.9250 - val_loss: 6.4549 - val_accuracy: 0.2091\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.3340 - accuracy: 0.9050 - val_loss: 6.6466 - val_accuracy: 0.1975\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.2632 - accuracy: 0.9400 - val_loss: 6.5507 - val_accuracy: 0.1993\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.2094 - accuracy: 0.9450 - val_loss: 6.1901 - val_accuracy: 0.2152\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.3736 - accuracy: 0.9000 - val_loss: 6.7809 - val_accuracy: 0.2208\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.2360 - accuracy: 0.9250 - val_loss: 6.7828 - val_accuracy: 0.2153\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.2857 - accuracy: 0.8950 - val_loss: 5.9467 - val_accuracy: 0.2217\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.2593 - accuracy: 0.9250 - val_loss: 6.3134 - val_accuracy: 0.2145\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.2474 - accuracy: 0.9050 - val_loss: 6.2489 - val_accuracy: 0.2292\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.1423 - accuracy: 0.9600 - val_loss: 6.4588 - val_accuracy: 0.2489\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 20s 7s/step - loss: 0.1822 - accuracy: 0.9450 - val_loss: 6.4508 - val_accuracy: 0.2596\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.1571 - accuracy: 0.9500 - val_loss: 6.3518 - val_accuracy: 0.2611\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.1022 - accuracy: 0.9750 - val_loss: 6.4887 - val_accuracy: 0.2554\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.1395 - accuracy: 0.9600 - val_loss: 6.6277 - val_accuracy: 0.2443\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.1319 - accuracy: 0.9600 - val_loss: 6.4494 - val_accuracy: 0.2422\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.1396 - accuracy: 0.9500 - val_loss: 6.3475 - val_accuracy: 0.2355\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 20s 7s/step - loss: 0.1013 - accuracy: 0.9700 - val_loss: 7.4126 - val_accuracy: 0.2196\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.2860 - accuracy: 0.9100 - val_loss: 8.0633 - val_accuracy: 0.2086\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f65a61fcf50>"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1.fit(x_train_normalized, y_train_onehot, validation_data=(x_test_normalized, y_test_onehot), batch_size=64, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C244NOgOqTQN"
      },
      "outputs": [],
      "source": [
        "model1.save(\"model1.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQ8w9v2Jzy6o"
      },
      "outputs": [],
      "source": [
        "# Q4, part 2\n",
        "def rotate(img, i):\n",
        "  # rotate image i * 90 degree times\n",
        "  y = np.zeros(4)\n",
        "  x = np.rot90(img, k=i)\n",
        "  y[i] = 1\n",
        "  return x, y\n",
        "\n",
        "def ssl_data(data):\n",
        "  x_rotated = []\n",
        "  y_rotated = []\n",
        "  for d in data:\n",
        "    for i in range(4):\n",
        "      x, y = rotate(d, i)\n",
        "      x_rotated.append(x)\n",
        "      y_rotated.append(y)\n",
        "    \n",
        "  return x_rotated, y_rotated\n",
        "\n",
        "x_rotated, y_rotated = ssl_data(x_unlabeld_normalized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AG2vOaZsfhVg",
        "outputId": "ce27f9dd-4958-4d5f-ac8a-5471434f81a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(199200, 32, 32, 3)\n",
            "(199200, 4)\n"
          ]
        }
      ],
      "source": [
        "x_rotated_arr = np.array(x_rotated)\n",
        "y_rotated_arr = np.array(y_rotated)\n",
        "\n",
        "# 4 train data for each image\n",
        "print(x_rotated_arr.shape)\n",
        "print(y_rotated_arr.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZZ-qGj3gKYY",
        "outputId": "61853c9e-7d2c-4b44-8156-c1759cf9c947"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                131136    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 420,196\n",
            "Trainable params: 419,300\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model2 = convolutional(0.2)\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
        "model2.add(Dense(4, activation='softmax'))\n",
        "\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkcbE7EVrIYh",
        "outputId": "0c165b12-033e-42d5-88df-4e2f3fb8352d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "779/779 [==============================] - 57s 58ms/step - loss: 0.9490 - accuracy: 0.6039\n",
            "Epoch 2/15\n",
            "779/779 [==============================] - 45s 58ms/step - loss: 0.7259 - accuracy: 0.7078\n",
            "Epoch 3/15\n",
            "779/779 [==============================] - 45s 57ms/step - loss: 0.6240 - accuracy: 0.7546\n",
            "Epoch 4/15\n",
            "779/779 [==============================] - 45s 58ms/step - loss: 0.5499 - accuracy: 0.7859\n",
            "Epoch 5/15\n",
            "779/779 [==============================] - 46s 59ms/step - loss: 0.4973 - accuracy: 0.8085\n",
            "Epoch 6/15\n",
            "779/779 [==============================] - 45s 58ms/step - loss: 0.4569 - accuracy: 0.8256\n",
            "Epoch 7/15\n",
            "779/779 [==============================] - 45s 57ms/step - loss: 0.4258 - accuracy: 0.8377\n",
            "Epoch 8/15\n",
            "779/779 [==============================] - 45s 57ms/step - loss: 0.4000 - accuracy: 0.8486\n",
            "Epoch 9/15\n",
            "779/779 [==============================] - 45s 57ms/step - loss: 0.3766 - accuracy: 0.8574\n",
            "Epoch 10/15\n",
            "779/779 [==============================] - 45s 57ms/step - loss: 0.3582 - accuracy: 0.8653\n",
            "Epoch 11/15\n",
            "779/779 [==============================] - 46s 59ms/step - loss: 0.3383 - accuracy: 0.8728\n",
            "Epoch 12/15\n",
            "779/779 [==============================] - 45s 57ms/step - loss: 0.3235 - accuracy: 0.8792\n",
            "Epoch 13/15\n",
            "779/779 [==============================] - 45s 57ms/step - loss: 0.3109 - accuracy: 0.8829\n",
            "Epoch 14/15\n",
            "779/779 [==============================] - 45s 58ms/step - loss: 0.2972 - accuracy: 0.8893\n",
            "Epoch 15/15\n",
            "779/779 [==============================] - 45s 57ms/step - loss: 0.2834 - accuracy: 0.8945\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0c1a36ac10>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "opt2 = Adam(learning_rate=0.001)\n",
        "\n",
        "model2.compile(optimizer=opt2, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model2.fit(x_rotated_arr, y_rotated_arr, batch_size=256, epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxPMI6voz1hQ"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "\n",
        "new_layer = Dense(10 ,activation='softmax')(model2.layers[-2].output)\n",
        "model2_2 = keras.Model(model2.inputs, new_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nchPxtFG0tN4",
        "outputId": "8b0ccfb4-aeaf-4e2c-b57f-1a40bd83779a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6_input (InputLayer)  [(None, 32, 32, 3)]      0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                131136    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 420,586\n",
            "Trainable params: 419,690\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model2_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AW2vizd-080g",
        "outputId": "9a9a2012-d926-480a-ded7-77abf4437e02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "4/4 [==============================] - 1s 26ms/step - loss: 14.3403 - accuracy: 0.1050\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 5.9600 - accuracy: 0.2150\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 2.0161 - accuracy: 0.4300\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1.3006 - accuracy: 0.5200\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1.0979 - accuracy: 0.6200\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.9804 - accuracy: 0.6750\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.7257 - accuracy: 0.7700\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.6137 - accuracy: 0.8100\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4860 - accuracy: 0.8300\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3491 - accuracy: 0.8900\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3106 - accuracy: 0.8950\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.2480 - accuracy: 0.9200\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.2178 - accuracy: 0.9300\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.1647 - accuracy: 0.9500\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.1897 - accuracy: 0.9200\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.1402 - accuracy: 0.9600\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.1278 - accuracy: 0.9700\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.1512 - accuracy: 0.9550\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.1121 - accuracy: 0.9700\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.1082 - accuracy: 0.9700\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.0980 - accuracy: 0.9700\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0624 - accuracy: 0.9800\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0603 - accuracy: 0.9800\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.0621 - accuracy: 0.9750\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.0971 - accuracy: 0.9750\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0389 - accuracy: 0.9950\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0708 - accuracy: 0.9850\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.0822 - accuracy: 0.9750\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0357 - accuracy: 0.9950\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0481 - accuracy: 0.9850\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0636 - accuracy: 0.9850\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.0413 - accuracy: 0.9900\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0405 - accuracy: 0.9900\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.0350 - accuracy: 0.9900\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0533 - accuracy: 0.9900\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0298 - accuracy: 0.9950\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0305 - accuracy: 0.9850\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.0197 - accuracy: 0.9950\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0218 - accuracy: 0.9900\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0160 - accuracy: 0.9950\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0163 - accuracy: 0.9950\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0122 - accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0162 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.0133 - accuracy: 0.9950\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0107 - accuracy: 0.9950\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0114 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0132 - accuracy: 0.9950\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0103 - accuracy: 0.9950\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0074 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0c1a359f50>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "model2_2.compile(optimizer=opt2, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model2_2.fit(x_train_normalized, y_train_onehot, batch_size=64, epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5nRILhICrjx",
        "outputId": "fc44f0c5-54f6-4bc8-a43d-c0e8d027aed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 10)\n",
            "(199200, 10)\n",
            "(200000, 32, 32, 3)\n",
            "(200000, 10)\n",
            "(200000, 4)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "# 200 images have class label, make rotations data too\n",
        "x_labeled_rotated, y_labeled_rotated = ssl_data(x_train_normalized)\n",
        "y_train_repeat = np.repeat(y_train, 4)\n",
        "y_train_repeat_onehot = to_categorical(y_train_repeat, num_classes=10)\n",
        "print(y_train_repeat_onehot.shape)\n",
        "\n",
        "# make class label (tensor of zeros) for unlabeled data\n",
        "y_unlabeld = np.zeros((x_unlabeld.shape[0]*4, 10))\n",
        "print(y_unlabeld.shape)\n",
        "\n",
        "# concatenate data\n",
        "x_train_all = np.concatenate((x_labeled_rotated, x_rotated_arr))\n",
        "y_train_class = np.concatenate((y_train_repeat_onehot, y_unlabeld))\n",
        "y_train_rotation = np.concatenate((y_labeled_rotated, y_rotated_arr))\n",
        "\n",
        "\n",
        "x_train_all, y_train_class, y_train_rotation = shuffle(x_train_all, y_train_class, y_train_rotation, random_state=20)\n",
        "print(x_train_all.shape)\n",
        "print(y_train_class.shape)\n",
        "print(y_train_rotation.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTiH9D_O-f7E",
        "outputId": "31686aff-18de-4a85-83fe-3d1e93be3299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " conv2d_6_input (InputLayer)    [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 32, 32, 32)   896         ['conv2d_6_input[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 32, 32, 32)  128         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 32, 32, 32)   9248        ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 32, 32, 32)  128         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 32)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 16, 16, 32)   0           ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 64)   18496       ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 64)  256         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 64)   36928       ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 64)  256         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 64)    0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 8, 8, 64)     0           ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 8, 8, 128)    73856       ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 8, 8, 128)   512         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 8, 8, 128)    147584      ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 8, 8, 128)   512         ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, 4, 4, 128)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 4, 4, 128)    0           ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 2048)         0           ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 128)          262272      ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " class_num_output (Dense)       (None, 10)           1290        ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " rotation_degree_output (Dense)  (None, 4)           516         ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 552,878\n",
            "Trainable params: 551,982\n",
            "Non-trainable params: 896\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Model\n",
        "\n",
        "base_model = convolutional(0.2)\n",
        "f = Flatten()(base_model.layers[-1].output)\n",
        "dense = Dense(128)(f)\n",
        "class_number = Dense(10, name='class_num_output')(dense)\n",
        "\n",
        "rotation_degree = Dense(4, name='rotation_degree_output')(dense)\n",
        "\n",
        "model3 = Model(inputs=base_model.input,\n",
        "               outputs = [class_number, rotation_degree])\n",
        "\n",
        "\n",
        "model3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nz7Kd0G8KPIe"
      },
      "outputs": [],
      "source": [
        "model3.compile(optimizer=opt, \n",
        "               loss={\n",
        "                   'class_num_output': 'categorical_crossentropy', \n",
        "                   'rotation_degree_output': 'categorical_crossentropy'},\n",
        "               loss_weights={\n",
        "                   'class_num_output': 2., \n",
        "                   'rotation_degree_output': 10.},\n",
        "               metrics={\n",
        "                   'class_num_output': 'accuracy',\n",
        "                   'rotation_degree_output': 'accuracy'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhV-GYT6cRLB",
        "outputId": "4853efc0-7b1a-4f60-93b4-0653c2f49eb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000,)\n",
            "(10000, 4)\n"
          ]
        }
      ],
      "source": [
        "r = 0\n",
        "y_test_rotation = np.repeat(r, y_test.shape[0])\n",
        "print(y_test_rotation.shape)\n",
        "y_test_rotation = to_categorical(y_test_rotation, num_classes=4)\n",
        "print(y_test_rotation.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUvcYN9DMxVT",
        "outputId": "fb3db254-110a-4cd8-ac40-27a98e2aa0c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 50s 62ms/step - loss: 77.5096 - class_num_output_loss: 0.0424 - rotation_degree_output_loss: 7.7425 - class_num_output_accuracy: 0.0011 - rotation_degree_output_accuracy: 0.2500 - val_loss: 64.1823 - val_class_num_output_loss: 11.2827 - val_rotation_degree_output_loss: 4.1617 - val_class_num_output_accuracy: 0.1000 - val_rotation_degree_output_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 48s 61ms/step - loss: 78.8335 - class_num_output_loss: 0.0451 - rotation_degree_output_loss: 7.8743 - class_num_output_accuracy: 4.0000e-04 - rotation_degree_output_accuracy: 0.2482 - val_loss: 93.3496 - val_class_num_output_loss: 11.2794 - val_rotation_degree_output_loss: 7.0791 - val_class_num_output_accuracy: 0.1000 - val_rotation_degree_output_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 48s 61ms/step - loss: 81.5652 - class_num_output_loss: 0.0441 - rotation_degree_output_loss: 8.1477 - class_num_output_accuracy: 4.0000e-04 - rotation_degree_output_accuracy: 0.2383 - val_loss: 137.5615 - val_class_num_output_loss: 10.5380 - val_rotation_degree_output_loss: 11.6485 - val_class_num_output_accuracy: 0.1000 - val_rotation_degree_output_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 48s 62ms/step - loss: nan - class_num_output_loss: nan - rotation_degree_output_loss: nan - class_num_output_accuracy: 0.9683 - rotation_degree_output_accuracy: 0.2498 - val_loss: nan - val_class_num_output_loss: nan - val_rotation_degree_output_loss: nan - val_class_num_output_accuracy: 0.1000 - val_rotation_degree_output_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 48s 62ms/step - loss: nan - class_num_output_loss: nan - rotation_degree_output_loss: nan - class_num_output_accuracy: 0.9964 - rotation_degree_output_accuracy: 0.2500 - val_loss: nan - val_class_num_output_loss: nan - val_rotation_degree_output_loss: nan - val_class_num_output_accuracy: 0.1000 - val_rotation_degree_output_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 48s 61ms/step - loss: nan - class_num_output_loss: nan - rotation_degree_output_loss: nan - class_num_output_accuracy: 0.9964 - rotation_degree_output_accuracy: 0.2500 - val_loss: nan - val_class_num_output_loss: nan - val_rotation_degree_output_loss: nan - val_class_num_output_accuracy: 0.1000 - val_rotation_degree_output_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 48s 61ms/step - loss: nan - class_num_output_loss: nan - rotation_degree_output_loss: nan - class_num_output_accuracy: 0.9964 - rotation_degree_output_accuracy: 0.2500 - val_loss: nan - val_class_num_output_loss: nan - val_rotation_degree_output_loss: nan - val_class_num_output_accuracy: 0.1000 - val_rotation_degree_output_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 48s 61ms/step - loss: nan - class_num_output_loss: nan - rotation_degree_output_loss: nan - class_num_output_accuracy: 0.9964 - rotation_degree_output_accuracy: 0.2500 - val_loss: nan - val_class_num_output_loss: nan - val_rotation_degree_output_loss: nan - val_class_num_output_accuracy: 0.1000 - val_rotation_degree_output_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 48s 61ms/step - loss: nan - class_num_output_loss: nan - rotation_degree_output_loss: nan - class_num_output_accuracy: 0.9964 - rotation_degree_output_accuracy: 0.2500 - val_loss: nan - val_class_num_output_loss: nan - val_rotation_degree_output_loss: nan - val_class_num_output_accuracy: 0.1000 - val_rotation_degree_output_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 47s 61ms/step - loss: nan - class_num_output_loss: nan - rotation_degree_output_loss: nan - class_num_output_accuracy: 0.9964 - rotation_degree_output_accuracy: 0.2500 - val_loss: nan - val_class_num_output_loss: nan - val_rotation_degree_output_loss: nan - val_class_num_output_accuracy: 0.1000 - val_rotation_degree_output_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "history3 = model3.fit(x_train_all, [y_train_class, y_train_rotation], validation_data=(x_test_normalized, [y_test_onehot, y_test_rotation]), batch_size=256, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.compile(optimizer=opt, \n",
        "               loss={\n",
        "                   'class_num_output': 'categorical_crossentropy', \n",
        "                   'rotation_degree_output': 'categorical_crossentropy'},\n",
        "               loss_weights={\n",
        "                   'class_num_output': 2., \n",
        "                   'rotation_degree_output': 5.},\n",
        "               metrics={\n",
        "                   'class_num_output': 'accuracy',\n",
        "                   'rotation_degree_output': 'accuracy'})"
      ],
      "metadata": {
        "id": "nMmHM_XKDRmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history3_2 = model3.fit(x_train_all, [y_train_class, y_train_rotation], validation_data=(x_test_normalized, [y_test_onehot, y_test_rotation]), batch_size=256, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEU2K_pUDbC6",
        "outputId": "a4961b48-5ec5-4b1f-b33e-fe742ac342ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 61s 63ms/step - loss: 8.1395 - class_num_output_loss: 0.0327 - rotation_degree_output_loss: 1.6148 - class_num_output_accuracy: 0.0182 - rotation_degree_output_accuracy: 0.2387 - val_loss: 23.3255 - val_class_num_output_loss: 8.0250 - val_rotation_degree_output_loss: 1.4551 - val_class_num_output_accuracy: 0.0969 - val_rotation_degree_output_accuracy: 0.0443\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 49s 62ms/step - loss: 7.2024 - class_num_output_loss: 0.0322 - rotation_degree_output_loss: 1.4276 - class_num_output_accuracy: 0.3450 - rotation_degree_output_accuracy: 0.2550 - val_loss: 25.1403 - val_class_num_output_loss: 9.1235 - val_rotation_degree_output_loss: 1.3787 - val_class_num_output_accuracy: 0.1223 - val_rotation_degree_output_accuracy: 0.1527\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 48s 62ms/step - loss: 7.4030 - class_num_output_loss: 0.0338 - rotation_degree_output_loss: 1.4671 - class_num_output_accuracy: 0.6344 - rotation_degree_output_accuracy: 0.2236 - val_loss: 22.7757 - val_class_num_output_loss: 8.0795 - val_rotation_degree_output_loss: 1.3233 - val_class_num_output_accuracy: 0.1136 - val_rotation_degree_output_accuracy: 0.1992\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 49s 62ms/step - loss: 7.2337 - class_num_output_loss: 0.0305 - rotation_degree_output_loss: 1.4345 - class_num_output_accuracy: 0.0230 - rotation_degree_output_accuracy: 0.2453 - val_loss: 23.3828 - val_class_num_output_loss: 8.1583 - val_rotation_degree_output_loss: 1.4132 - val_class_num_output_accuracy: 0.1066 - val_rotation_degree_output_accuracy: 0.0032\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 48s 62ms/step - loss: 7.0868 - class_num_output_loss: 0.0299 - rotation_degree_output_loss: 1.4054 - class_num_output_accuracy: 0.0640 - rotation_degree_output_accuracy: 0.2439 - val_loss: 22.4813 - val_class_num_output_loss: 7.7901 - val_rotation_degree_output_loss: 1.3802 - val_class_num_output_accuracy: 0.0978 - val_rotation_degree_output_accuracy: 0.0798\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 48s 62ms/step - loss: 7.2846 - class_num_output_loss: 0.0321 - rotation_degree_output_loss: 1.4441 - class_num_output_accuracy: 0.0108 - rotation_degree_output_accuracy: 0.2430 - val_loss: 23.1699 - val_class_num_output_loss: 7.9788 - val_rotation_degree_output_loss: 1.4424 - val_class_num_output_accuracy: 0.0926 - val_rotation_degree_output_accuracy: 0.0247\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 48s 62ms/step - loss: 7.1982 - class_num_output_loss: 0.0314 - rotation_degree_output_loss: 1.4271 - class_num_output_accuracy: 0.0090 - rotation_degree_output_accuracy: 0.2236 - val_loss: 23.1231 - val_class_num_output_loss: 8.0795 - val_rotation_degree_output_loss: 1.3928 - val_class_num_output_accuracy: 0.0897 - val_rotation_degree_output_accuracy: 0.0305\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 48s 61ms/step - loss: 7.1248 - class_num_output_loss: 0.0321 - rotation_degree_output_loss: 1.4121 - class_num_output_accuracy: 0.0048 - rotation_degree_output_accuracy: 0.2524 - val_loss: 22.6550 - val_class_num_output_loss: 8.0796 - val_rotation_degree_output_loss: 1.2991 - val_class_num_output_accuracy: 0.1029 - val_rotation_degree_output_accuracy: 0.0349\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 48s 62ms/step - loss: 7.0325 - class_num_output_loss: 0.0324 - rotation_degree_output_loss: 1.3935 - class_num_output_accuracy: 4.2000e-04 - rotation_degree_output_accuracy: 0.2491 - val_loss: 23.0125 - val_class_num_output_loss: 8.0875 - val_rotation_degree_output_loss: 1.3675 - val_class_num_output_accuracy: 0.1028 - val_rotation_degree_output_accuracy: 0.0262\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 48s 62ms/step - loss: 7.0048 - class_num_output_loss: 0.0323 - rotation_degree_output_loss: 1.3880 - class_num_output_accuracy: 4.2500e-04 - rotation_degree_output_accuracy: 0.2505 - val_loss: 23.0972 - val_class_num_output_loss: 8.0861 - val_rotation_degree_output_loss: 1.3850 - val_class_num_output_accuracy: 0.1027 - val_rotation_degree_output_accuracy: 0.0253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.compile(optimizer=opt, \n",
        "               loss={\n",
        "                   'class_num_output': 'categorical_crossentropy', \n",
        "                   'rotation_degree_output': 'categorical_crossentropy'},\n",
        "               loss_weights={\n",
        "                   'class_num_output': 2., \n",
        "                   'rotation_degree_output': 0.5},\n",
        "               metrics={\n",
        "                   'class_num_output': 'accuracy',\n",
        "                   'rotation_degree_output': 'accuracy'})"
      ],
      "metadata": {
        "id": "inuDexhub5kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history3_3 = model3.fit(x_train_all, [y_train_class, y_train_rotation], validation_data=(x_test_normalized, [y_test_onehot, y_test_rotation]), batch_size=256, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUQinzWycDtq",
        "outputId": "da3a72aa-50ad-447c-a375-171c8919f141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 75s 81ms/step - loss: 4.1085 - class_num_output_loss: 0.0339 - rotation_degree_output_loss: 8.0816 - class_num_output_accuracy: 5.1000e-04 - rotation_degree_output_accuracy: 0.2523 - val_loss: 23.0698 - val_class_num_output_loss: 7.7657 - val_rotation_degree_output_loss: 15.0769 - val_class_num_output_accuracy: 0.1014 - val_rotation_degree_output_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 61s 78ms/step - loss: 4.1117 - class_num_output_loss: 0.0338 - rotation_degree_output_loss: 8.0881 - class_num_output_accuracy: 5.5000e-04 - rotation_degree_output_accuracy: 0.2520 - val_loss: 23.0811 - val_class_num_output_loss: 7.7657 - val_rotation_degree_output_loss: 15.0994 - val_class_num_output_accuracy: 0.1009 - val_rotation_degree_output_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 61s 78ms/step - loss: 4.1089 - class_num_output_loss: 0.0342 - rotation_degree_output_loss: 8.0812 - class_num_output_accuracy: 5.3500e-04 - rotation_degree_output_accuracy: 0.2515 - val_loss: 23.0674 - val_class_num_output_loss: 7.7609 - val_rotation_degree_output_loss: 15.0914 - val_class_num_output_accuracy: 0.1008 - val_rotation_degree_output_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 61s 79ms/step - loss: 4.1169 - class_num_output_loss: 0.0335 - rotation_degree_output_loss: 8.0997 - class_num_output_accuracy: 5.1000e-04 - rotation_degree_output_accuracy: 0.2522 - val_loss: 23.0787 - val_class_num_output_loss: 7.7641 - val_rotation_degree_output_loss: 15.1010 - val_class_num_output_accuracy: 0.1008 - val_rotation_degree_output_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 61s 79ms/step - loss: 4.1182 - class_num_output_loss: 0.0332 - rotation_degree_output_loss: 8.1036 - class_num_output_accuracy: 5.3000e-04 - rotation_degree_output_accuracy: 0.2519 - val_loss: 23.0618 - val_class_num_output_loss: 7.7641 - val_rotation_degree_output_loss: 15.0672 - val_class_num_output_accuracy: 0.1010 - val_rotation_degree_output_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 62s 79ms/step - loss: 4.1147 - class_num_output_loss: 0.0333 - rotation_degree_output_loss: 8.0964 - class_num_output_accuracy: 5.1000e-04 - rotation_degree_output_accuracy: 0.2525 - val_loss: 23.0698 - val_class_num_output_loss: 7.7593 - val_rotation_degree_output_loss: 15.1027 - val_class_num_output_accuracy: 0.1009 - val_rotation_degree_output_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 62s 79ms/step - loss: 4.1197 - class_num_output_loss: 0.0344 - rotation_degree_output_loss: 8.1018 - class_num_output_accuracy: 5.3000e-04 - rotation_degree_output_accuracy: 0.2522 - val_loss: 23.0585 - val_class_num_output_loss: 7.7576 - val_rotation_degree_output_loss: 15.0865 - val_class_num_output_accuracy: 0.1010 - val_rotation_degree_output_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 61s 78ms/step - loss: 4.1125 - class_num_output_loss: 0.0330 - rotation_degree_output_loss: 8.0927 - class_num_output_accuracy: 5.1500e-04 - rotation_degree_output_accuracy: 0.2522 - val_loss: 23.0513 - val_class_num_output_loss: 7.7512 - val_rotation_degree_output_loss: 15.0978 - val_class_num_output_accuracy: 0.1009 - val_rotation_degree_output_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 61s 79ms/step - loss: 4.1132 - class_num_output_loss: 0.0332 - rotation_degree_output_loss: 8.0935 - class_num_output_accuracy: 5.2000e-04 - rotation_degree_output_accuracy: 0.2524 - val_loss: 23.0835 - val_class_num_output_loss: 7.7673 - val_rotation_degree_output_loss: 15.0978 - val_class_num_output_accuracy: 0.1007 - val_rotation_degree_output_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 62s 79ms/step - loss: 4.1136 - class_num_output_loss: 0.0328 - rotation_degree_output_loss: 8.0960 - class_num_output_accuracy: 5.1500e-04 - rotation_degree_output_accuracy: 0.2522 - val_loss: 23.0787 - val_class_num_output_loss: 7.7657 - val_rotation_degree_output_loss: 15.0946 - val_class_num_output_accuracy: 0.1011 - val_rotation_degree_output_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DL-HW13-q3-q4.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}